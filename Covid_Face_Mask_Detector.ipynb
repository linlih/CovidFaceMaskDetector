{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid Face Mask Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8CUvQSLMppgvS9wBe1UNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linlih/CovidFaceMaskDetector/blob/master/Covid_Face_Mask_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHkTq00Vxoh",
        "colab_type": "text"
      },
      "source": [
        "# 下载数据\n",
        "\n",
        "数据来源：https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsSlIPIvVpTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpfo5MQHXzZl",
        "colab_type": "code",
        "outputId": "8f7aa376-ce9f-4531-9a7e-457af994c565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "datasetPath = Path('./data/mask.zip')\n",
        "# 从GoogleDrive的共享文件中下载训练数据\n",
        "gdd.download_file_from_google_drive(file_id='1UlOk6EtiaXTHylRUx2mySgvJX9ycoeBp',\n",
        "                  dest_path=str(datasetPath),\n",
        "                  unzip=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1UlOk6EtiaXTHylRUx2mySgvJX9ycoeBp into data/mask.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihBIAXqTX8rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetPath.unlink() # 删除下载的zipwe文件"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7M-QSMkYa5a",
        "colab_type": "code",
        "outputId": "d77a189e-a137-48e2-96d8-97b3852d588d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 构建DataFrame，并保存序列化，如果序列化过了，就无需无需执行这个内容，直接读入序列化的文件即可\n",
        "# 注意DataFrame的append是要赋值等号的形式：maskDF = maskDF.append(xxx)，这个使用形式和其他直接append无法赋值就生效的不一致，要十分注意\n",
        "datasetPath = Path('./data/self-built-masked-face-recognition-dataset')\n",
        "maskPath = datasetPath/'AFDB_masked_face_dataset'\n",
        "nonMaskPath = datasetPath/'AFDB_face_dataset'\n",
        "\n",
        "maskDF = pd.DataFrame()\n",
        "\n",
        "for subject in tqdm(list(maskPath.iterdir()),desc='mask photos'):\n",
        "  for imgPath in subject.iterdir():\n",
        "    maskDF = maskDF.append({\n",
        "        'image': str(imgPath),\n",
        "        'mask': 1\n",
        "    }, ignore_index=True)\n",
        "\n",
        "for subject in tqdm(list(nonMaskPath.iterdir()),desc='no mask photos'):\n",
        "  for imgPath in subject.iterdir():\n",
        "    maskDF = maskDF.append({\n",
        "        'image': str(imgPath),\n",
        "        'mask': 0\n",
        "    }, ignore_index=True)\n",
        "    \n",
        "dfName = './data/mask_df.pickle'\n",
        "print(f'saving DataFrame to {dfName}')\n",
        "maskDF.to_pickle(dfName) # 保存序列化文件，读取的函数使用pd.read_pickle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mask photos: 100%|██████████| 525/525 [00:05<00:00, 92.19it/s]\n",
            "no mask photos: 100%|██████████| 460/460 [04:33<00:00,  1.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving DataFrame to ./data/mask_df.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayv1AWz9sRWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 如果已经序列化过，直接执行这个创建DataFrame即可\n",
        "maskDF = pd.read_pickle('./data/mask_df.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuRrFpqOp7R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 统计结果中共有戴口罩的人脸图片是2203张，正常人脸是90468张\n",
        "# 和Github数据集上说明的5千张戴口罩和9万张正常人脸有一定的出入\n",
        "maskDF['mask'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I34ThlqxuRxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建Dataset，这里是为了能够让PyTorch进行读取\n",
        "import cv2\n",
        "from torch import long, tensor\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmRxgFryvcEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskDataset(Dataset):\n",
        "  def __init__(self, dataFrame):\n",
        "    self.dataFrame = dataFrame\n",
        "    self.transformations = Compose([\n",
        "        ToPILImage(),\n",
        "        Resize((100, 100)), # 每张人脸的大小调整为100*100\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    \n",
        "  def __getitem__(self, key):\n",
        "    if isinstance(key, slice):\n",
        "      raise NotImplementedError('slicing is not supported')\n",
        "    row = self.dataFrame.iloc[key]\n",
        "    return {\n",
        "        'image': self.transformations(cv2.imread(row['image'])),\n",
        "        'mask': tensor([row['mask']], dtype=long)\n",
        "    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataFrame.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5NefYqaw_TR",
        "colab_type": "code",
        "outputId": "89679912-b783-4c59-db6b-28190f008217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install pytorch-lightning -q"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 256kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 8.8MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgn90swxwaZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建模型\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import Tensor\n",
        "from torch.nn import (Conv2d, CrossEntropyLoss, Linear, MaxPool2d, ReLU, Sequential)\n",
        "from torch.optim import Adam\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qJHYp07wtRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskDetector(pl.LightningModule):\n",
        "  def __init__(self, maskDFPath: Path=None):\n",
        "    super(MaskDetector, self).__init__()\n",
        "    self.maskDFPath = maskDFPath\n",
        "    self.maskDF = None\n",
        "    self.trainDF = None\n",
        "    self.validationDF = None\n",
        "    self.crossEntropyLoss = None\n",
        "    self.learningRate = 0.00001\n",
        "\n",
        "    self.convLayer1 = convLayer1 = Sequential(Conv2d(3, 32, kernel_size=(3, 3), padding=(1, 1)),\n",
        "                           ReLU(),\n",
        "                           MaxPool2d(kernel_size=(2, 2))\n",
        "                           )\n",
        "    self.convLayer2 = convLayer2 = Sequential(Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1)),\n",
        "                           ReLU(),\n",
        "                           MaxPool2d(kernel_size=(2, 2))\n",
        "                           )\n",
        "    self.convLayer3 = convLayer3 = Sequential(Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1), stride=(3, 3)),\n",
        "                           ReLU(),\n",
        "                           MaxPool2d(kernel_size=(2, 2))\n",
        "                           )\n",
        "    self.linearLayers = linearLayers = Sequential(Linear(in_features=2048, out_features=1024),\n",
        "                            ReLU(),\n",
        "                            Linear(in_features=1024, out_features=2))\n",
        "    \n",
        "    for sequential in [convLayer1, convLayer2, convLayer3, linearLayers]:\n",
        "      for layer in sequential.children():\n",
        "        if isinstance(layer, (Linear, Conv2d)):\n",
        "          init.xavier_uniform_(layer.weight)\n",
        "  \n",
        "  def forward(self, x: Tensor):\n",
        "    out = self.convLayer1(x)\n",
        "    out = self.convLayer2(out)\n",
        "    out = self.convLayer3(out)\n",
        "    out = out.view(-1, 2048)\n",
        "    out = self.linearLayers(out)\n",
        "    return out\n",
        "  \n",
        "  def prepare_data(self) -> None:\n",
        "    self.maskDF = maskDF = pd.read_pickle(self.maskDFPath)\n",
        "    train, validate = train_test_split(maskDF, test_size=0.3, random_state=0, stratify=maskDF['mask'])\n",
        "    self.trainDF = MaskDataset(train)\n",
        "    self.validateDF = MaskDataset(validate)\n",
        "\n",
        "    maskNum = maskDF[maskDF['mask'] == 1].shape[0]\n",
        "    nonMaskNum = maskDF[maskDF['mask'] == 0].shape[0]\n",
        "    nSamples = [nonMaskNum, maskNum]\n",
        "    normedWeights = [1 - (x/sum(nSamples)) for x in nSamples]\n",
        "    self.crossEntropyLoss = CrossEntropyLoss(weight=torch.tensor(normedWeights))\n",
        "\n",
        "  def train_dataloader(self) -> DataLoader:\n",
        "    return DataLoader(self.trainDF, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "  def val_dataloader(self) -> DataLoader:\n",
        "    return DataLoader(self.validateDF, batch_size=32, num_workers=4)\n",
        "  \n",
        "  def configure_optimizers(self) -> Optimizer:\n",
        "    return Adam(self.parameters(), lr=self.learningRate)\n",
        "\n",
        "  def training_step(self, batch: dict, _batch_idx: int) -> Dict[str, Tensor]:\n",
        "    inputs, labels = batch['image'], batch['mask']\n",
        "    labels = labels.flatten()\n",
        "    outputs = self.forward(inputs)\n",
        "    loss = self.crossEntropyLoss(outputs, labels)\n",
        "    \n",
        "    tensorboardLogs = {'train_loss': loss}\n",
        "    return {'loss': loss, 'log': tensorboardLogs}\n",
        "\n",
        "  def validation_step(self, batch:dict, _batch_idx: int) -> Dict[str, Tensor]:\n",
        "    inputs, labels = batch['image'], batch['mask']\n",
        "    labels = labels.flatten()\n",
        "    outputs = self.forward(inputs)\n",
        "    loss = self.crossEntropyLoss(outputs, labels)\n",
        "\n",
        "    _, outputs = torch.max(outputs, dim=1)\n",
        "    valAcc = accuracy_score(outputs.cpu(), labels.cpu())\n",
        "    valAcc = torch.tensor(valAcc)\n",
        "    return {'val_loss': loss, 'val_acc': valAcc}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs: List[Dict[str, Tensor]]) \\\n",
        "     -> Dict[str, Union[Tensor, Dict[str, Tensor]]]:\n",
        "    avgLoss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "    avgAcc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "    tensorboardLogs = {'val_loss': avgLoss, 'val_acc': avgAcc}\n",
        "    return {'val_loss':avgLoss, 'log': tensorboardLogs}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0rCOCFuZ7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# colab在这里训练会卡死\n",
        "# 提示是JavaScript失效或者google账号登录失效之类的\n",
        "# 很奇怪的是，这个训练一运行，本地的内存被吃光了，训练不是放在Colab云端进行的吗，这里只是做了个显示而已，为什么会把本地的内存全部用完，有点莫名其妙\n",
        "model = MaskDetector(Path('./data/mask_df.pickle'))\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = './checkpoints/weights.ckpt',\n",
        "    save_weights_only=True,\n",
        "    verbose=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max'\n",
        ")\n",
        "trainer = Trainer(gpus=1,\n",
        "          max_epochs=10,\n",
        "          checkpoint_callback=checkpoint_callback,\n",
        "          profiler=True)\n",
        "trainer.fit(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQS4yxEUvAqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 下载训练好的模型\n",
        "!wget https://raw.githubusercontent.com/JadHADDAD92/covid-mask-detector/master/covid-mask-detector/models/face_mask.ckpt # 人脸口罩检测模型\n",
        "!wget https://raw.githubusercontent.com/JadHADDAD92/covid-mask-detector/master/covid-mask-detector/models/deploy.prototxt.txt # OpenCV人脸检测\n",
        "!wget https://raw.githubusercontent.com/JadHADDAD92/covid-mask-detector/master/covid-mask-detector/models/res10_300x300_ssd_iter_140000.caffemodel # OpenCV人脸检测"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3HUdWHH7J1M",
        "colab_type": "text"
      },
      "source": [
        "由于在Colab不能实时处理webcam的图像，下面的实现方法是进行拍照，然后将得到的图片进行检测是否有佩戴口罩，如果是在本地运行的话，可以使用OpenCV进行实时检测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDdH5e6G8F66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 参考代码：在Colab中显示webcam的内容，测试用，不需要执行\n",
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "      \n",
        "start_webcam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JUoUp_-omuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google官方提供的webcam获取函数，支持拍照，测试用，不需要执行\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUkEs5LPq_HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from cv2 import resize\n",
        "from cv2.dnn import blobFromImage, readNetFromCaffe\n",
        "\n",
        "class FaceDetectorException(Exception):\n",
        "  \"\"\" generic default exception\n",
        "  \"\"\"\n",
        "\n",
        "# 人脸检测，这里使用的是OpenCV提供的人脸检测模型\n",
        "class FaceDetector:\n",
        "  \"\"\" Face Detector class\n",
        "  \"\"\"\n",
        "  def __init__(self, prototype: Path=None, model: Path=None,\n",
        "                confidenceThreshold: float=0.6):\n",
        "    self.prototype = prototype\n",
        "    self.model = model\n",
        "    self.confidenceThreshold = confidenceThreshold\n",
        "    if self.prototype is None:\n",
        "        raise FaceDetectorException(\"must specify prototype '.prototxt.txt' file \"\n",
        "                                    \"path\")\n",
        "    if self.model is None:\n",
        "        raise FaceDetectorException(\"must specify model '.caffemodel' file path\")\n",
        "    self.classifier = readNetFromCaffe(str(prototype), str(model))\n",
        "  \n",
        "  def detect(self, image):\n",
        "    \"\"\" detect faces in image\n",
        "    \"\"\"\n",
        "    net = self.classifier\n",
        "    height, width = image.shape[:2]\n",
        "    blob = blobFromImage(resize(image, (300, 300)), 1.0,\n",
        "                          (300, 300), (104.0, 177.0, 123.0))\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "    faces = []\n",
        "    for i in range(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence < self.confidenceThreshold:\n",
        "            continue\n",
        "        box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
        "        startX, startY, endX, endY = box.astype(\"int\")\n",
        "        faces.append(np.array([startX, startY, endX-startX, endY-startY]))\n",
        "    return faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ww1ymB0zqe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import click\n",
        "import cv2\n",
        "import torch\n",
        "#from skvideo.io import FFmpegWriter, vreader\n",
        "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import cv2\n",
        "\n",
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "\n",
        "      div.appendChild(video);\n",
        "\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      img = document.createElement('img');\n",
        "      div_out.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgb64){\n",
        "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n",
        "\n",
        "def byte2image(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "def image2byte(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x\n",
        "\n",
        "VideoCapture()\n",
        "eval_js('create()')\n",
        "\n",
        "modelpath='/content/face_mask.ckpt'\n",
        "outputPath=None\n",
        "\n",
        "model = MaskDetector()\n",
        "model.load_state_dict(torch.load(modelpath), strict=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "faceDetector = FaceDetector(\n",
        "    prototype='./deploy.prototxt.txt',\n",
        "    model='./res10_300x300_ssd_iter_140000.caffemodel',\n",
        ")\n",
        "\n",
        "transformations = Compose([\n",
        "    ToPILImage(),\n",
        "    Resize((100, 100)),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "if outputPath:\n",
        "    writer = FFmpegWriter(str(outputPath))\n",
        "\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "labels = ['No mask', 'Mask']\n",
        "labelColor = [(10, 0, 255), (10, 255, 0)]\n",
        "\n",
        "while True:\n",
        "  byte = eval_js('capture()')\n",
        "  frame = byte2image(byte)\n",
        "  #print(im.shape)\n",
        "  faces = faceDetector.detect(frame)\n",
        "\n",
        "  for face in faces:\n",
        "    xStart, yStart, width, height = face\n",
        "    #print(face)\n",
        "    # clamp coordinates that are outside of the image\n",
        "    xStart, yStart = max(xStart, 0), max(yStart, 0)\n",
        "    \n",
        "    # predict mask label on extracted face\n",
        "    faceImg = frame[yStart:yStart+height, xStart:xStart+width]\n",
        "    output = model(transformations(faceImg).unsqueeze(0).to(device))\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    \n",
        "    # draw face frame\n",
        "    cv2.rectangle(frame,\n",
        "            (xStart, yStart),\n",
        "            (xStart + width, yStart + height),\n",
        "            (126, 65, 64),\n",
        "          thickness=2)\n",
        "    \n",
        "    # center text according to the face frame\n",
        "    textSize = cv2.getTextSize(labels[predicted], font, 1, 2)[0]\n",
        "    textX = xStart + width // 2 - textSize[0] // 2\n",
        "    \n",
        "    # draw prediction label\n",
        "    cv2.putText(frame,\n",
        "          labels[predicted],\n",
        "          (textX, yStart-20),\n",
        "          font, 1, labelColor[predicted], 2)\n",
        "    if outputPath:\n",
        "        writer.writeFrame(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "    eval_js('showimg(\"{}\")'.format(image2byte(frame)))\n",
        "  if outputPath:\n",
        "      writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}